{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance\n",
    "%pip install matplotlib\n",
    "%pip install pandas numpy\n",
    "%pip install --upgrade sympy torch\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install ripser\n",
    "\n",
    "# 3. Restart runtime again\n",
    "\n",
    "# 4. Now import and run your code\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPOLOGICAL DATA ANALYSIS (RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Topological Data Analysis (TDA) from Scratch\n",
    "Uses ripser (lightweight C++ library) for persistent homology\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Install lightweight ripser library\n",
    "# !pip install ripser\n",
    "\n",
    "try:\n",
    "    from ripser import ripser\n",
    "    RIPSER_AVAILABLE = True\n",
    "    print(\"✅ Ripser library available\")\n",
    "except ImportError:\n",
    "    RIPSER_AVAILABLE = False\n",
    "    print(\"⚠️ Install ripser: pip install ripser\")\n",
    "\n",
    "# ==================== TAKENS EMBEDDING ====================\n",
    "\n",
    "def takens_embedding(time_series, embedding_dim=3, time_delay=1):\n",
    "    \"\"\"\n",
    "    Create Takens embedding (phase space reconstruction)\n",
    "    \n",
    "    Args:\n",
    "        time_series: 1D numpy array\n",
    "        embedding_dim: dimension of embedding\n",
    "        time_delay: time delay between coordinates\n",
    "        \n",
    "    Returns:\n",
    "        2D array of shape (n_points, embedding_dim)\n",
    "    \"\"\"\n",
    "    n = len(time_series)\n",
    "    m = n - (embedding_dim - 1) * time_delay\n",
    "    \n",
    "    if m <= 0:\n",
    "        raise ValueError(\"Time series too short for given embedding parameters\")\n",
    "    \n",
    "    embedded = np.zeros((m, embedding_dim))\n",
    "    for i in range(m):\n",
    "        for j in range(embedding_dim):\n",
    "            embedded[i, j] = time_series[i + j * time_delay]\n",
    "    \n",
    "    return embedded\n",
    "\n",
    "\n",
    "# ==================== PERSISTENT HOMOLOGY ====================\n",
    "\n",
    "def compute_persistence_diagrams(point_cloud, max_dimension=1, max_edge_length=None):\n",
    "    \"\"\"\n",
    "    Compute persistence diagrams using Vietoris-Rips complex\n",
    "    \n",
    "    Args:\n",
    "        point_cloud: 2D array of points\n",
    "        max_dimension: maximum homology dimension to compute\n",
    "        max_edge_length: maximum edge length in Rips complex\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with persistence diagrams for each dimension\n",
    "    \"\"\"\n",
    "    if not RIPSER_AVAILABLE:\n",
    "        raise ImportError(\"ripser not installed. Run: pip install ripser\")\n",
    "    \n",
    "    # Compute persistence using ripser\n",
    "    result = ripser(point_cloud, maxdim=max_dimension, thresh=max_edge_length)\n",
    "    \n",
    "    return result['dgms']\n",
    "\n",
    "\n",
    "# ==================== FEATURE EXTRACTION FROM DIAGRAMS ====================\n",
    "\n",
    "def persistence_entropy(diagram, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute persistence entropy\n",
    "    \n",
    "    Measures the distribution of lifetimes of topological features\n",
    "    High entropy = many features with similar lifetimes\n",
    "    Low entropy = few dominant features\n",
    "    \"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Remove infinite points\n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute lifetimes (persistence)\n",
    "    lifetimes = diagram[:, 1] - diagram[:, 0]\n",
    "    \n",
    "    # Remove zero lifetimes\n",
    "    lifetimes = lifetimes[lifetimes > 0]\n",
    "    \n",
    "    if len(lifetimes) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Normalize to get probability distribution\n",
    "    if normalize:\n",
    "        lifetimes = lifetimes / np.sum(lifetimes)\n",
    "    \n",
    "    # Compute entropy\n",
    "    entropy = -np.sum(lifetimes * np.log(lifetimes + 1e-10))\n",
    "    \n",
    "    return float(entropy)\n",
    "\n",
    "\n",
    "def persistence_landscape(diagram, k=1, resolution=100):\n",
    "    \"\"\"\n",
    "    Compute k-th persistence landscape\n",
    "    \n",
    "    Landscapes are functional summaries of persistence diagrams\n",
    "    \"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return np.zeros(resolution)\n",
    "    \n",
    "    # Remove infinite points\n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    if len(diagram) == 0:\n",
    "        return np.zeros(resolution)\n",
    "    \n",
    "    # Create grid\n",
    "    births = diagram[:, 0]\n",
    "    deaths = diagram[:, 1]\n",
    "    min_val = np.min(births)\n",
    "    max_val = np.max(deaths)\n",
    "    \n",
    "    grid = np.linspace(min_val, max_val, resolution)\n",
    "    \n",
    "    # Compute landscape functions for each point\n",
    "    landscapes = []\n",
    "    for birth, death in zip(births, deaths):\n",
    "        midpoint = (birth + death) / 2\n",
    "        height = (death - birth) / 2\n",
    "        \n",
    "        # Triangle function\n",
    "        landscape = np.zeros(resolution)\n",
    "        for i, t in enumerate(grid):\n",
    "            if birth <= t <= midpoint:\n",
    "                landscape[i] = (t - birth)\n",
    "            elif midpoint < t <= death:\n",
    "                landscape[i] = (death - t)\n",
    "        \n",
    "        landscapes.append(landscape)\n",
    "    \n",
    "    # Sort and take k-th landscape\n",
    "    landscapes = np.array(landscapes)\n",
    "    if len(landscapes) < k:\n",
    "        return np.zeros(resolution)\n",
    "    \n",
    "    # Sort at each time point\n",
    "    sorted_landscapes = np.sort(landscapes, axis=0)[::-1]\n",
    "    \n",
    "    return sorted_landscapes[k-1] if k <= len(sorted_landscapes) else np.zeros(resolution)\n",
    "\n",
    "\n",
    "def betti_numbers(diagram, t):\n",
    "    \"\"\"\n",
    "    Compute Betti number at filtration value t\n",
    "    \n",
    "    Betti number = number of topological features alive at time t\n",
    "    - Betti-0: number of connected components\n",
    "    - Betti-1: number of holes/loops\n",
    "    \"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Remove infinite points\n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    # Count features born before t and dying after t\n",
    "    alive = np.sum((diagram[:, 0] <= t) & (diagram[:, 1] > t))\n",
    "    \n",
    "    return int(alive)\n",
    "\n",
    "\n",
    "def max_persistence(diagram):\n",
    "    \"\"\"Maximum persistence (lifetime) of any feature\"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    lifetimes = diagram[:, 1] - diagram[:, 0]\n",
    "    return float(np.max(lifetimes))\n",
    "\n",
    "\n",
    "def total_persistence(diagram, power=1):\n",
    "    \"\"\"\n",
    "    Total persistence (sum of all lifetimes)\n",
    "    \n",
    "    Args:\n",
    "        power: exponent to apply to lifetimes (1=sum, 2=sum of squares, etc.)\n",
    "    \"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    if len(diagram) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    lifetimes = diagram[:, 1] - diagram[:, 0]\n",
    "    return float(np.sum(lifetimes ** power))\n",
    "\n",
    "\n",
    "def number_of_features(diagram, threshold=0.0):\n",
    "    \"\"\"Count features with persistence above threshold\"\"\"\n",
    "    if len(diagram) == 0:\n",
    "        return 0\n",
    "    \n",
    "    diagram = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "    \n",
    "    if len(diagram) == 0:\n",
    "        return 0\n",
    "    \n",
    "    lifetimes = diagram[:, 1] - diagram[:, 0]\n",
    "    return int(np.sum(lifetimes > threshold))\n",
    "\n",
    "\n",
    "# ==================== COMPLETE TDA FEATURE EXTRACTOR ====================\n",
    "\n",
    "class TDAFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Complete TDA feature extractor using ripser\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim=3, time_delay=1, max_homology_dim=1):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.time_delay = time_delay\n",
    "        self.max_homology_dim = max_homology_dim\n",
    "        \n",
    "    def extract_features(self, time_series):\n",
    "        \"\"\"\n",
    "        Extract comprehensive TDA features from time series\n",
    "        \n",
    "        Returns:\n",
    "            numpy array of 12 features:\n",
    "            - H0 entropy\n",
    "            - H1 entropy  \n",
    "            - H0 max persistence\n",
    "            - H1 max persistence\n",
    "            - H0 total persistence\n",
    "            - H1 total persistence\n",
    "            - H0 number of features\n",
    "            - H1 number of features\n",
    "            - H0 landscape amplitude\n",
    "            - H1 landscape amplitude\n",
    "            - H0 betti number (at midpoint)\n",
    "            - H1 betti number (at midpoint)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Takens embedding\n",
    "            embedded = takens_embedding(time_series, self.embedding_dim, self.time_delay)\n",
    "            \n",
    "            # Step 2: Compute persistence diagrams\n",
    "            diagrams = compute_persistence_diagrams(embedded, \n",
    "                                                   max_dimension=self.max_homology_dim,\n",
    "                                                   max_edge_length=np.inf)\n",
    "            \n",
    "            # Step 3: Extract features from each homology dimension\n",
    "            features = []\n",
    "            \n",
    "            for dim in range(self.max_homology_dim + 1):\n",
    "                diagram = diagrams[dim]\n",
    "                \n",
    "                # Entropy\n",
    "                features.append(persistence_entropy(diagram))\n",
    "                \n",
    "                # Max persistence\n",
    "                features.append(max_persistence(diagram))\n",
    "                \n",
    "                # Total persistence\n",
    "                features.append(total_persistence(diagram, power=1))\n",
    "                \n",
    "                # Number of significant features\n",
    "                threshold = 0.1 * max_persistence(diagram) if len(diagram) > 0 else 0.0\n",
    "                features.append(float(number_of_features(diagram, threshold)))\n",
    "                \n",
    "                # Landscape amplitude\n",
    "                landscape = persistence_landscape(diagram, k=1, resolution=50)\n",
    "                features.append(float(np.max(landscape)) if len(landscape) > 0 else 0.0)\n",
    "                \n",
    "                # Betti number at midpoint of filtration\n",
    "                if len(diagram) > 0:\n",
    "                    diagram_finite = diagram[np.isfinite(diagram).all(axis=1)]\n",
    "                    if len(diagram_finite) > 0:\n",
    "                        midpoint = (np.min(diagram_finite[:, 0]) + np.max(diagram_finite[:, 1])) / 2\n",
    "                        features.append(float(betti_numbers(diagram, midpoint)))\n",
    "                    else:\n",
    "                        features.append(0.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "            \n",
    "            return np.array(features[:12], dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: TDA extraction failed: {e}\")\n",
    "            return np.zeros(12, dtype=np.float32)\n",
    "\n",
    "\n",
    "# ==================== TESTING ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing TDA from Scratch\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test 1: Simple sine wave (should have periodic structure)\n",
    "    print(\"\\n1. Testing on sine wave (periodic signal):\")\n",
    "    t = np.linspace(0, 4 * np.pi, 100)\n",
    "    sine_wave = np.sin(t) + 0.1 * np.random.randn(100)\n",
    "    \n",
    "    extractor = TDAFeatureExtractor(embedding_dim=3, time_delay=2, max_homology_dim=1)\n",
    "    features_sine = extractor.extract_features(sine_wave)\n",
    "    \n",
    "    print(f\"   Features extracted: {features_sine}\")\n",
    "    print(f\"   H0 entropy: {features_sine[0]:.4f}\")\n",
    "    print(f\"   H1 entropy: {features_sine[1]:.4f}\")\n",
    "    print(f\"   H1 max persistence: {features_sine[3]:.4f} (should be > 0 for periodic)\")\n",
    "    \n",
    "    # Test 2: Random noise (should have minimal structure)\n",
    "    print(\"\\n2. Testing on random noise:\")\n",
    "    noise = np.random.randn(100)\n",
    "    \n",
    "    features_noise = extractor.extract_features(noise)\n",
    "    \n",
    "    print(f\"   Features extracted: {features_noise}\")\n",
    "    print(f\"   H0 entropy: {features_noise[0]:.4f}\")\n",
    "    print(f\"   H1 entropy: {features_noise[1]:.4f}\")\n",
    "    print(f\"   H1 max persistence: {features_noise[3]:.4f} (should be ~0 for noise)\")\n",
    "    \n",
    "    # Test 3: Trend (should show different topology)\n",
    "    print(\"\\n3. Testing on trend:\")\n",
    "    trend = np.linspace(0, 10, 100) + 0.5 * np.random.randn(100)\n",
    "    \n",
    "    features_trend = extractor.extract_features(trend)\n",
    "    \n",
    "    print(f\"   Features extracted: {features_trend}\")\n",
    "    print(f\"   H0 entropy: {features_trend[0]:.4f}\")\n",
    "    print(f\"   H1 max persistence: {features_trend[3]:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ TDA from scratch is working!\")\n",
    "    print(\"\\nKey insights:\")\n",
    "    print(\"- Periodic signals show H1 features (loops in phase space)\")\n",
    "    print(\"- Random noise shows minimal topological structure\")\n",
    "    print(\"- Different dynamics produce different topological signatures\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
